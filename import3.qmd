# Importing Data - Part 3 {#sec-import3}
  
::: {.callout-note appearance="simple"}
Today we will focus on the practice of importing data - with examples for class projects.
:::
    
## Load libraries and install new package

Load `tidyverse`, `sf`, `leaflet`, and `htmltools`.  

```{r}
#| label: load libraries
#| echo: true

library(tidyverse)
library(sf)
library(leaflet)
library(htmltools)

```
    
I will also demonstrate the use of the [`tidycensus`] package. Install and load the `tidycensus` package.  

```{r}
#| label: install tidycensus
#| echo: true
#| eval: false

install.packages('tidycensus')

```

```{r}
#| label: load tidycensus
#| echo: true

library(tidycensus)

```

### Extra step - register for API key from the Census

Register at this url [https://api.census.gov/data/key_signup.html](https://api.census.gov/data/key_signup.html).

Organization is probably Pitzer College.

Check your email for a very long api key. Copy that key.

Run the following line of code to activate your key for the session. The key is used in every request to access data from the census API (application programming interface).

```{r}
#| label: census api key
#| echo: true
#| eval: false
#| message: false


# Replace <YOUR KEY HERE> with the key from the census data api service
census_api_key('<YOUR KEY HERE>', install = TRUE)


```

```{r}
#| label: census api key for real
#| echo: false
#| eval: false

census_api_key('b5554d6b880d7233a664782c7931421460b3f82f', install = TRUE)

```

## Import Geospatial Census data

`tidycensus` allows one to pull specific geospatial census datasets quickly into R for use in mapping and visualization applications.  This should be pretty good for the individual and group projects.

First, we need to alter a setting in the options to allow R to directly import geospatial files from the census API.  

```{r}
#| label: tigris
#| echo: true

options(tigris_use_cache = TRUE)
```

### Example 1 - Los Angeles census tracts

`tidycensus` accepts state names (e.g. "Wisconsin"), state postal codes (e.g. "WI"), and state FIPS codes (e.g. "55"), so a user can choose what they are most comfortable with.

First, let's pull a census tract dataset to show how it works and how it quickly gets us spatial information. I will start with an example from Los Angeles County. We are pulling American Community Survey data using `get_acs()`.  The arguments are `state`, `county`, `geography` - which we choose as census tract, `variable` - which we choose as _B19013_001_ which is median income, `geometry`, and `year`.  

```{r}
#| label: get ACS data for LA County
#| echo: true
#| message: false

LA <- get_acs(
  state = "CA",
  county = "Los Angeles",
  geography = "tract",
  variables = "B19013_001",
  geometry = TRUE,
  year = 2020
)

```

Now let's map it using leaflet. I want to show the median income as a filled color and I'll choose the `viridis` palette.  Remember to define the color palette first. @fig-income shows the result.

```{r}
#| label: fig-income
#| echo: true
#| fig-cap: Median income for 2015-2020 for Los Angeles County - data from the ACS

palIncome <- colorNumeric(palette = 'magma', domain = LA$estimate)

LA %>% 
  filter(!is.na(estimate)) %>% 
  st_transform("+proj=longlat +ellps=WGS84 +datum=WGS84") %>%
  leaflet() %>% 
  addTiles() %>% 
  addPolygons(color = ~palIncome(estimate),
              fillOpacity = 0.5,
              weight = 1,
              label = ~htmlEscape(str_c('$',estimate))) %>% 
  addLegend(pal = palIncome,
            title = 'Median Income',
            values = ~estimate)

```

The variables that are available from the U.S. census can be perused using the following code bits.  See the `tidycensus` page for more details. There are 25,000+ variables to choose from and it goes a bit too deep to go into those here.   

```{r}
#| label: explore census variables
#| echo: true

v20 <- load_variables(2020, "acs5", cache = TRUE)

head(v20)
#View(v20)
```


### Example 2 - Jefferson County, Texas - Racial variables

Knowing income is nice, but a lot of the analysis was focused on racial variables.  Here's an example for Jefferson County, Texas to pull decennial census data on racial composition at the county census tract level. 

```{r}
#| label: pull racial variables
#| echo: TRUE
#| message: FALSE

# These are the list of racial variables from the decennial census
racevars <- c(White = "P2_005N", 
              Black = "P2_006N", 
              Asian = "P2_008N", 
              Hispanic = "P2_002N")

JeffCo <- get_decennial(
  geography = "tract",
  variables = racevars,
  state = "TX",
  county = "Jefferson County",
  geometry = TRUE,
  summary_var = "P2_001N",
  year = 2020
) 

head(JeffCo)
```
Data looks good.  @fig-JeffCoRace shows a facet wrap display of the racial data. This is a very modest remix of the example from the `tidycensus` spatial data example for [Harris County](https://walker-data.com/tidycensus/articles/spatial-data.html).  

```{r}
#| label: fig-JeffCoRace
#| echo: true
#| fig-cap: Racial demographic information for Jefferson County, Texas from the decennial census for 2020.

JeffCo %>%
  #Create a percent variable for the four racial categories
  mutate(percent = 100 * (value / summary_value)) %>%
  ggplot(aes(fill = percent)) +
  facet_wrap(~variable) +
  geom_sf(color = NA) +
  theme_void() + 
  scale_fill_viridis_c() + 
  labs(fill = "% of population\n(2020 Census)")

```

This is a good start, especially if one overlaid the location of major petrochemical facilities from the TRI dataset on it. 

### Example from Cancer Alley

[TorHoerman Law](https://www.torhoermanlaw.com/cancer-alley-causes-and-effects-of-chemical-corridor-in-louisiana/) identifies three parishes in Louisiana as part of cancer alley - St. Charles, St. James, and St. John the Baptist.  

Can we pull and display three parishes (i.e., Louisiana county equivalents) simultaneously?

```{r}
#| label: cancer alley pull
#| echo: true
#| message: FALSE

#Note, we use the same racial demographic variables in previous example

#Combine the three parishes into a single list for pulling
parishes <- c('St. John the Baptist',
              'St. James',
              'St. Charles')

CancerAlley <- get_decennial(
  geography = "tract",
  variables = racevars,
  #change the state
  state = "LA",
  #change the county 
  county = parishes,
  geometry = TRUE,
  summary_var = "P2_001N",
  year = 2020
) 

head(CancerAlley)
```

The data looks promising.  Opening the new **CancerAlley** table shows that there are census tracts from each of the parishes listed. @fig-Alley shows the same style of display for Cancer Alley as display for Jefferson County, TX. Note that Ascenscion and Iberville Parishes may warrant inclusion as well.   

```{r}
#| label: fig-Alley
#| echo: true
#| fig-cap: Racial demographic information for Cancer Alley from the decennial census for 2020.

CancerAlley %>%
  #Create a percent variable for the four racial categories
  mutate(percent = 100 * (value / summary_value)) %>%
  ggplot(aes(fill = percent)) +
  facet_wrap(~variable) +
  #included tract lines for clarity
  geom_sf(color = 'black') +
  theme_void() + 
  scale_fill_viridis_c() + 
  labs(fill = "% of population\n(2020 Census)")

```

### Example 3. Air Toxics Monitoring Data

I dropped a file in everyone's Box.  This is really just for the folks on Team Sacrifice.

First, open the .RData file by selecting it and double-clicking it.  This should open a new RStudio session.  

In the _Environment_ panel, there should now be a dataset named **annual_risk** with 108,343 observations of 20 variables.  Please **WHOOT** if that is present.

The **annual_risk** table has cancer risk values in units of excess cases per million people. But it does not have site latitude and longitude information. The **site_list** table has that information. We can join those two files based on the _aqs_sitecode_ field which is common to both files.

The code below is a lot of individual steps, most of which we have discussed before. @fig-Benzene shows the cancer risk at all US monitors that measured benzene for a full year in 2020.    

```{r}
#| label: fig-Benzene
#| echo: true
#| fig-cap: Benzene annual cancer risk at all valid 2020 measurement sites.

load(url('https://github.com/RadicalResearchLLC/Toxics_dashboard/raw/master/ToxicsDashboard/.RData'))

# the annual_risk dataset has cancer risk for all air toxics by year and site
annual_risk %>% 
  #joining to site_list to get lat/long and site name info
  left_join(site_list) %>% 
  #only keep the year 2019
  filter(yr == 2019) %>% 
  #only keep the parameter Benzene
  filter(parameter == 'Benzene') %>% 
  #make a map
  leaflet() %>% 
  addTiles() %>%
  #show circles that are proportional to cancer risk with label hoverable label info 
  addCircles(weight = 1, 
             color = 'red',
             #radius * 3000 was arrived at by trial and error - circles were too small with lower numbers
             radius = ~cancerRisk * 3000, 
             #paste() function used to show site name and cancer risk, round trims excess decimal point values
             label = ~htmlEscape(paste(local_site_name, round(cancerRisk, 1))))

```


### Example 4 - [LA County Open Data Portal](https://data.lacounty.gov/search?categories=open%20data%2Chydro&q=water)

I looked through some of the sources of data the Debt Team was trying to access. I am not a water domain expert, so I wanted simpler data sources.  The LA County Open Data Portal has a set of Hydro data layers that may be of use.

One promising dataset was the [ground water basins layer](https://data.lacounty.gov/datasets/lacounty::ground-water-basins-feature-layer/explore?location=34.049054%2C-117.335615%2C8.36). I download a `GeoJSON` file format.  

1. Download file - mine was named `Ground_Water_Basins_Feature_Layer.geojson`
2. Move to working directory
3. Read file using `read_sf()`
4. Transform file to WGS84 using `st_transform()`
5. Make a map using `leaflet()` as shown in @fig-groundwaterBasins

```{r}
#| label: fig-groundwaterBasins
#| echo: true
#| fig-cap: groundwater basins in LA county

groundH2O <- read_sf(dsn = 'Ground_Water_Basins_Feature_Layer.geojson') %>% 
   st_transform("+proj=longlat +ellps=WGS84 +datum=WGS84") 

groundH2O %>% 
  leaflet() %>% 
  addTiles() %>% 
  addPolygons(weight = 2,
              label = ~htmlEscape(BASIN))

```

### Example 5. Aqueducts in California

California Natural Resources Agency Open Data portal has an [aqueduct layer](https://data.cnra.ca.gov/dataset/i12-canals-and-aqueducts-local1).

Repeat the steps from Example 4.  

1. Download file - mine was named `i12_Canals_and_Aqueducts_local.geojson`
2. Move to working directory
3. Read file using `read_sf()`
4. Transform file to WGS84 using `st_transform()`
5. Make a map using `leaflet()` as shown in @fig-aqueducts - 
6. Refine map to only show aqueducts that serve LA County - a 5 minute attempt is shown here, getting it right may require [research](https://www.watereducation.org/aquapedia/california-aqueduct)

```{r}
#| label: fig-aqueducts
#| echo: true
#| fig-cap: Aqueducts providing water to LA county

aqua <- read_sf(dsn = 'i12_Canals_and_Aqueducts_local.geojson') %>% 
   st_transform("+proj=longlat +ellps=WGS84 +datum=WGS84") 

#Team Debt needs to fill this in.
LACounty_aqua <- c('Main Canal', 'Los Angeles Aqueduct', 'Colorado River Aqueduct')

aqua %>% 
  filter(Name %in% LACounty_aqua) %>% 
  leaflet() %>% 
  addTiles() %>% 
  addPolylines(weight = 2,
              label = ~htmlEscape(Name))
```
